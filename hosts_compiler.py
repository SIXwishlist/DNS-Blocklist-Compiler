import threadmedaddy
import tldextract, os
from urllib.request import urlopen, URLError, HTTPError

# Ensures we are using the correct code page in windows console!
os.system("chcp 65001")

__HOSTS_HEADER = '# grufwubs combined hosts\n127.0.0.1 localhost\n::1 localhost\n\n# Start of entries generated by download_stripped_hosts.py\n'
__HOSTS_DOWNLOAD_LIST = 'sources_list.txt'
__BACKUP_DIR = 'backups/'
__BACKUP_EXT = '.txt'
__OUTPUT_DIR = 'compiled/'
__OUTPUT_FILE = 'hosts'
__GLOBAL_WHITELIST = dict()

def parse_sources_file(file_name):
	bl = list()
	wl = list()
	
	f = open(file_name, 'r')
	for line in f.read().split('\n'):
		line_split = line.split(':')
		source_type = line_split[0]
		
		if source_type == 'blacklist':
			bl.append(line_split[1])
			
		if source_type == 'whitelist':
			wl.append(line_split[1])
	
	f.close()
	return bl, wl

def build_backup_file_str(url):
	return __BACKUP_DIR + url + __BACKUP_EXT

def download_hosts(source_url):
	hl = list()
	
	try:
		#  Try downloading new data
		response = urlopen(source_url)
		raw = response.read()
		text = raw.decode('utf-8')
	except HTTPError | URLError:
		# Downloading new data failed ):
		print('Unable to download hosts from %s. Retrieving saved backup...' % source_url)
		file_str = build_backup_file_str(source_url)
		
		if not os.path.exists(file_str):
			print('There is no saved backup for %s!' % source_url)
			return
		
		f = open(file_str, 'r')
		text = f.read()
	
	for line in text.split('\n'):
		hl.append(line)
	
	return hl

def backup_to_file(file_str, hosts):
	# do some thingsss

def process_host(host):
	# Skip unusable lines
	if not host:
		return

	# Strips any whitespace
	host = host.strip()
	# Strips initial pipe symbols
	host = host.replace('|', '')
	# Strips initial '0.0.0.0 ' / '127.0.0.1 ' from host files
	host = host.replace('0.0.0.0 ', '')
	host = host.replace('127.0.0.1 ', '')

	if '#' in host:
	# Skips comment lines and lines blocking specific CSS items
	if host.startswith('#') or '##' in host:
		return
	else:
		host = host.split('#')[0] # Removes excess comment strings located after host

	if '^' in host:
		if host.endswith('^third-party'):
			host = host.replace('^third-party', '')
		elif host.endswith('^$important'):
			host = host.replace('^$important', '')
		else:
			if host.endswith('^'):
				host = host.replace('^', '')
			else:
				return

	if '$' in host:
		return
	if '!' in host:
		return
	if ':' in host:
		return
	if '@' in host:
		return
	if '*' in host:
		return
	if '?' in host:
		return
	if '=' in host:
		return
	if '[' in host:
		return
	if ']' in host:
		return
	if ',' in host:
		return
	if '/' in host:
		return
	if '(' in host:
		return
	if ')' in host:
		return
	if ';' in host:
		return
	if '%' in host:
		return
	if '{' in host:
		return
	if '{' in host:
		return

	# Skips final unusables
	if host.startswith('.') or host.endswith('.'):
		return

	# Adds the host to a dictionary which serves as the value to a parent dictionary (passed in the method argument), with the registered domain as the key
	ext = tldextract.extract(host)
	base_domain = ext.registered_domain
	if base_domain == '' or base_domain == '\n' or base_domain == ' ':
		return
	
	return host

def run():
	bl_list, wl_list = parse_sources_file(__HOSTS_DOWNLOAD_LIST)
	blacklist = list()
	whitelist = list()
	
	print('Downloading blacklists...')
	for url in bl_list:
		hosts = download_hosts(url)
		blacklist.extend(hosts)
		backup_to_file( build_backup_file_str(url) , hosts)
	print('Done!')
	
	print('Downloading whitelists...')
	for url in wl_list:
		hosts = download_hosts(url)
		whitelist.extend(hosts)
		backup_to_file( build_backup_file_str(url) , hosts)
	print('Done!')
	
	mt = threadmedaddy.MultiThreader()
	mt.add_data((blacklist)
	mt.set_function(process_host)
	mt.run()
	print('Finished multithreaded operation! (:')
	
	compiled_hosts = mt.get_processed_data()
	backup_to_file(__OUTPUT_FILE, compiled_hosts)
	print('Finished writing compiled hosts to file! (:')
